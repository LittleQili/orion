04/05/2023 16:43:34 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/transformer/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:43:34 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:43:58 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/transformer/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:43:58 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:44:52 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/transformer/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:44:52 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:53:21 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "~/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:53:21 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:54:00 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "~/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:54:00 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:54:19 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "~/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:54:19 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:55:28 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 16:55:28 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 16:57:20 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 16:57:20 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 16:57:20 INFO    : [train_transformer.py:204] transformer is set up with 2000
04/05/2023 17:00:41 INFO    : [main.py:98] full config:
{
    "policy": "MPS-process",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:00:41 INFO    : [main.py:100] train transformer and train vision using MPS-process
04/05/2023 17:00:50 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:00:50 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:00:50 INFO    : [train_transformer.py:204] transformer is set up with 2000
04/05/2023 17:02:35 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:02:35 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:02:44 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:02:44 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:02:44 INFO    : [train_transformer.py:204] transformer is set up with 2000
04/05/2023 17:03:42 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:03:42 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:03:51 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:03:51 INFO    : [train_transformer.py:161] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:03:51 INFO    : [train_transformer.py:204] transformer is set up with 2000
04/05/2023 17:04:33 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:04:33 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:04:42 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:04:42 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:04:43 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:05:50 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:05:50 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:06:13 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:06:13 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:06:22 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:06:22 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:06:22 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:06:46 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:06:46 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:06:55 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:06:55 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:06:56 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:07:44 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:07:44 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:07:54 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:07:54 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:07:54 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:09:46 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:09:46 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:09:52 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:09:52 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:09:53 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:10:30 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:10:30 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:10:36 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:10:36 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:10:36 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:11:24 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:11:24 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:11:30 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:11:30 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:11:30 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:12:37 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:12:37 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:12:44 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:12:44 INFO    : [train_transformer.py:162] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:12:44 INFO    : [train_transformer.py:205] transformer is set up with 2000
04/05/2023 17:13:16 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:13:16 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:13:22 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:13:22 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:13:22 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:15:21 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:15:21 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:15:28 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:15:28 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:15:28 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:15:42 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:15:42 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:15:48 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:15:48 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:15:48 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:15:59 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:15:59 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:16:05 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:16:05 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:16:06 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:16:22 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:16:22 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:16:28 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:16:28 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:16:28 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:16:44 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:16:44 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:16:50 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:16:50 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:16:50 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:17:06 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:17:06 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:17:12 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:17:12 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:17:12 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:17:49 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:17:49 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:17:55 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:17:55 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:17:55 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:18:25 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:18:25 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:18:31 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:18:31 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:18:31 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:23:53 INFO    : [train_transformer.py:277] tid 0 it takes 320.02557826042175 seconds to train transformer
04/05/2023 17:26:11 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:26:11 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:26:17 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:26:17 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:26:17 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:27:42 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:27:42 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:27:48 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:27:48 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:27:48 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:27:55 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 2000,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:27:55 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:28:01 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:28:01 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:28:02 INFO    : [train_transformer.py:230] transformer is set up with 2000
04/05/2023 17:29:58 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:29:58 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:30:04 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:30:04 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:30:05 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 17:30:35 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:30:35 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:30:42 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:30:42 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:30:42 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 17:32:06 INFO    : [train_transformer.py:278] tid 0 it takes 82.50074076652527 seconds to train transformer
04/05/2023 17:32:30 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:32:30 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:32:36 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:32:36 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:32:36 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 17:34:03 INFO    : [train_transformer.py:278] tid 0 it takes 84.16851711273193 seconds to train transformer
04/05/2023 17:35:14 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:35:14 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:35:20 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:35:20 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:35:20 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 17:36:51 INFO    : [train_transformer.py:278] tid 0 it takes 88.47513389587402 seconds to train transformer
04/05/2023 17:37:22 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:37:22 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:37:32 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:37:32 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:37:32 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 17:39:02 INFO    : [train_transformer.py:278] tid 0 it takes 88.16331577301025 seconds to train transformer
04/05/2023 17:39:32 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 17:39:32 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 17:39:41 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:39:41 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 17:39:42 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 17:41:20 INFO    : [train_transformer.py:278] tid 0 it takes 96.39909291267395 seconds to train transformer
04/05/2023 20:56:30 INFO    : [main.py:98] full config:
{
    "policy": "temporal",
    "model0": {
        "mode": "train",
        "name": "transformer"
    },
    "model1": {
        "mode": "train",
        "name": "vision"
    },
    "num_epochs": 1,
    "shared_config": {
        "imagenet_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/imagenet/imagenet-raw-euwest4/train",
        "cifar10_root": "/cluster/scratch/xianma/cifar10",
        "squad_version1": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v1.1/train-v1.1.json",
        "squad_version2": "/mnt/disks/disk-imagenet-gpu-share/home/fot/squad/v2.0/train-v2.0.json",
        "wmt16_en_de_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16",
        "coco_root": "/mnt/disks/disk-imagenet-gpu-share/home/fot/coco2017",
        "wikitext_103_dir": "/home/image-varuna/DeepLearningExamples/PyTorch/LanguageModeling/Transformer-XL/data/wikitext-103",
        "print_every": 100,
        "enable_profiling": false,
        "use_dummy_data": true,
        "num_requests": 200,
        "num_warm_up_reqs": 20,
        "request_rate": 10,
        "percentile_positions": [
            90,
            95,
            99
        ]
    },
    "nasnet": {
        "optimizer": "SGD",
        "batch_size": 32,
        "arc": "mobile",
        "num_workers": 2
    },
    "vision": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "vision1": {
        "arc": "mobilenet_v2",
        "optimizer": "SGD",
        "batch_size": 32,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20
    },
    "dcgan": {
        "num_gen_filters": 64,
        "num_dis_filters": 64,
        "latent_z_vec_size": 100,
        "batch_size": 32,
        "optimizer": "Adam",
        "input_image_size": 64,
        "dataset": "imagenet",
        "num_workers": 2
    },
    "gnmt": {
        "math": "fp32",
        "batch_size": 128,
        "num_workers": 2,
        "num_iterations": 200,
        "warm_up_iters": 20,
        "dummy_datum_path": "/mnt/disks/disk-imagenet-gpu-share/home/fot/wmt16/gnmt_datum.pt"
    },
    "bert": {
        "use_fp16": false,
        "fp16_loss_scale": 0,
        "squad_version": 2,
        "batch_size": 16,
        "num_workers": 2,
        "arch": "base",
        "num_iterations": 200,
        "warm_up_iters": 20,
        "large_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-24_H-1024_A-16",
        "base_model_dir": "/mnt/disks/disk-imagenet-gpu-share/home/fot/bert/download/google_pretrained_weights/uncased_L-12_H-768_A-12"
    },
    "transformer": {
        "arch": "base",
        "use_fp16": false,
        "amp": "apex",
        "apex_amp_opt_level": "O2",
        "batch_size": 8,
        "num_iterations": 500,
        "warm_up_iters": 10
    },
    "retinanet": {
        "dataset_name": "coco",
        "use_amp": false,
        "num_workers": 2,
        "batch_size": 8,
        "num_iterations": 200,
        "warm_up_iters": 20
    }
}
04/05/2023 20:56:30 INFO    : [main.py:100] train transformer and train vision using temporal
04/05/2023 20:56:39 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 20:56:39 INFO    : [train_transformer.py:187] part of dummy data shape: torch.Size([192, 8])
04/05/2023 20:56:40 INFO    : [train_transformer.py:230] transformer is set up with 500
04/05/2023 20:58:19 INFO    : [train_transformer.py:278] tid 0 it takes 96.88879942893982 seconds to train transformer
